Today: **Midterm (a week from today)**, basics of internet protocols and the web (faster)

# Networks
For the first time, we are talking about running on multiple, rather than 1, computers. What are your options model-wise? 

### Client-Server
Server is in charge of maintaining the state, single authority, allows to coordinate, server always knows the current state of the system. Earliest Form.

### Peer-to-Peer
Distribute the data amongst the peers, more complex. Maybe everyone is responsible for a certain type? 

### Primary-Secondery computing 
Primary assigns to all the seconderies work, so that data compunicates back up to primary. 

## New issues for networks
3 options 

1. **Preformence**: Overhead for shipping data. For us, not a huge issue. Matters in production, on large demanding apps. Two aspects to preformence
    1. *Throughput*: how much work can your application do per second? (operation per second, def operation depends on your app). Generally meassures server-side. Of course, you'll want to maximize. 
    How to improve throughput? add more nodes, things improve in parallal.
    2. *Latency*: Time difference between request and response. How to improve? cheat and cache data, i.e. avoid the actual request.

    To some extent, these are competing objectives. Throughput increase for example, to wait a bunch of request and process them all together. 
2. **Correctness**: supposed we do *out-of-order execution* to increase latency (or throughput?) Here's an example:
    
        imagine $c_1$ requests before $c_2$, but $c_2$ gets faster to the $s$. What if $c_2$ request changes the response for $c_1$'s?

    we use *serialization* to solve, where serialization is **I am not sure** something like explaining system action based on the order... Maybe you are trying to do something based on chache that is no longer accurate (trying to buy a ticket that is cached as avalabile, but no longer is). Most chaches can be somewhat out of order (Google maps, for example, not money or anything important).  

    Problem of *cache validation* some chache on the server, wanna know how correct it is, just asking server is not efficient. 

3. **Security** The hardest of the 3. Skip for now.


## History of Networks
Brief overview of CS 118.

### Circuit Switching 
Phone in LA wants to call NY. The whole mux-demux operation, but with extra steps (middle stations along the way). You have to relay across many many stations. While the call is going on, nobody can use those wires. *A lot of ouppurtunity for sharing*.

### Packet Switching 
You don't reserve wire exclusively. Take $m$ and divide it into $n$ 100Kb packets. Dump packets into network, s.t packets are somehow gonna get to NY (maybe some part of $m$ specifies that), they "eventually" arrive at NY, perhaps not in the order we sent them, perhaps some got "lost."

Each packet is treated independently, the route of each packet is done differently. *It's the recipent's job to make sense of the jumble of packets they get* (deal with duplication, order chance, and loss of packages). A traditional phone is not enough! You need more intelligence. 

Paul Baran proposed (1962), built (1969) here at UCLA. 

Problem of Buecracy: many manufacturers, didn't want to bow down to anyone else's standards. Architectures very different. Need a peace treaty to allow this network to exist and devices to talk to one another. Called the 

### Internet Protocol Suite 
Protocol, coming from deplomacy (trying not to offend one of the other companies). Specified in the Internet *Request For Commments (RFC)* -- didn't want to offend anyone (here's an idea send me comments for improvement). Do it this way if you want to work with the rest of the world. The constituition of the internet. 

Basic idea: *When possible, we try to build these protocols out of layers (of abstraction)*, we can't think precisely of "what bit." Levels (low to high):

1. *Link layer* talks about what happens between 2 nodes. hardware oriented
2. *Internet layer* talks about individual packets, that could be sent from anywhere anywhere else
3. *transport layer* Having data channels. Abstract the mess of packets. new york is reacieving LA is sending 
4. *application layer* We take the (channels and packets and tailor it for an application) application layer for web-browsers


### Protocols: networks: APIs: Program 
*API* is a contract betwen a user and an implementation. higher leverl, just what u give what u get. You don't need to, and often don't get to, know the underlyings. 

### Zoom in: Internet Protocol (at the internet level)
IPv4 and IPv6 We focus on 4. Everything connected to internet, we have a 32 bit integer written in 8-bit number. Supposudly unique. (RFC 791 -- 1981 -- Jon Postel)

A packet contains the header and contents, where the header has sender's IP add, recipients IPaddr. Protocol number -- to support highr level protocols. TTL -- time to live (?), hop count, too many places, packet dropped -- Prevent infinite loops areound. Has a checksumn (16-bit) --  for data integrity -- catch transmittion erros. Parity of some packet area.

RFC 8200 (2017) 128-bit IP address (less efficient, but we need new adresses!) + other stuff. Current internet is a hybrid. 


### Zoom in: Transport layer
UDP (User Datagram Protocol) RFC 768. Thin layer over IP. For application that want to send packets and nothing else. (closer to 2 than 3). 

TCP (Transmition control protocol) RFC 793 (Vint Cerf, Bob Kohn) For application that want more than that. We want to have data channels, we want to know it gets there. 
- Provides stream of data which is realiable (ship out data, the other guy gets it, but in realit ythere is re-asking for lost data, but user doesn;t know or care) 
- Ordered
- Error-checked (has it's own checksum) *fundemental property each layer doesn't trust the next layer down when it comes to data integrity* -- too many screwups. 

Has to: 
- divide into packages
- reasembley reasemble packets in correct order
- retransmition if package lost -- resend. 
- *hardest part:* transmission control. *flow control* sender may have a lot of packets to send, but it shouldn't send them all at once becuase router would drop them. *collective property rather than individual property*. TCP didn;t actully get it right. 

Many protocls are built atop TCP/IP -- mostly commonly used transport layer protocls. Examples: 
- RTP -- real time transport protocol. Stripped TCP designed for video stream. Varient for TCP. Specified RFC 3550 (2003). Reasonable real-time preformence, willing to give up realiability, some data may be lost, we are okay with that (some pixels missing, but rather keep watching). TCP would cause gitter due to the re-transmission. (ZOOM is a varinet).
- HTTP more later

## The world wide web (WWW)
Tim Berners-Lee (CERN, 1991). Came up with a protocol, HTTP, and HTML (data format). 

### HTTP (1.0)
Very simple protocol request/response

    `GET index.html HTTP1`

Header at the HTTP layer, and body. iterations of additional features HTTP 3 is upcoming. HTML has evolved. Where the pressure come from? What is the reason for these changes? What to use to be bleeding edge. 

HTTP/1.1 (RFCs 7230-7235)

Nowdays, HTTPS is more popular, it encrypts the data from client to server and vice versa. Diffie-Helman!

In HTTP/2: 

- transport efficiency 
- server push (server can message u don;t have to check all the time)
- pipelining send 3 request at once (one header), all in a batch, speed. Disatvantage -- wrong order. 
- Multiplexing: Independence of tabs with 1 HTTP connection to the same server. 

QUIC bypassing the TLS TCP layers (stil IP ). QUIC version1 just replaces them but isn't HTTP. HTTP 3 ontop of QUIC v1 (RFCs 9000-9002 MAY 2021). 

### HTML 
HyperTextMetaLanguage, took from SGML (standard generalized markup language). cross publisher text

## Random Stuff (commands and whatever)

## Questions

1. I have an I don't know somewhere, find it!